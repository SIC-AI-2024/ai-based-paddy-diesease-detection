{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3656f7-125e-43fa-806a-86c8e7e08047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import uuid\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0ea40-7132-40c4-9f1f-717da6e41676",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY_LIST = [\n",
    " 'black_stem_borer',\n",
    " 'white_stem_borer',\n",
    " 'bacterial_panicle_blight',\n",
    " 'bacterial_leaf_blight',\n",
    " 'brown_spot',\n",
    " 'leaf_roller',\n",
    " 'hispa',\n",
    " 'downy_mildew',\n",
    " 'blast',\n",
    " 'normal',\n",
    " 'bacterial_leaf_streak',\n",
    " 'tungro',\n",
    " 'yellow_stem_borer'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d1fa6-799e-4980-88a3-42337b08ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_dir = os.path.join('data','paddy-doctor-diseases-small')\n",
    "input_data_dir_list = [os.path.join(input_data_dir,directory) for directory in DIRECTORY_LIST]\n",
    "input_metadata_file_path = os.path.join(input_data_dir,'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25906993-afb7-407e-89ff-7c3033b38640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date and time for a unique directory name\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "output_data_dir = os.path.join('data', f'paddy-doctor-diseases-augmented_{timestamp}')\n",
    "output_metadata_file_path = os.path.join(output_data_dir, 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b07d83-4981-412b-8b07-4c4a8f6b6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new output directory\n",
    "os.makedirs(output_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5bb408-7648-4810-a888-eb1ff3572693",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_pipeline = A.Compose([\n",
    "    A.Resize(256, 256),  # Resize images to a fixed size of 256x256\n",
    "    A.HorizontalFlip(p=0.5),  # Flip image horizontally with a 50% chance\n",
    "    A.VerticalFlip(p=0.5),  # Flip image vertically with a 50% chance\n",
    "    A.Rotate(limit=30, p=0.5),  # Rotate image within a range of -30 to 30 degrees\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.3),  # Apply Gaussian blur with a 30% chance\n",
    "    A.RandomBrightnessContrast(p=0.5),  # Randomly adjust brightness and contrast with a 50% chance\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),  # Randomly adjust hue, saturation, and value\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=0, p=0.5),  # Shift and scale image without rotation\n",
    "    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),  # Apply grid distortion for a warping effect with a 50% chance\n",
    "    A.OpticalDistortion(distort_limit=0.2, shift_limit=0.2, p=0.1),  # Simulate optical distortions like lens effects\n",
    "    A.ChannelShuffle(p=0.1),  # Shuffle color channels for varied color effects with a 30% chance\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.3),  # Randomly adjust gamma values to control brightness intensity\n",
    "    A.Equalize(p=0.3),  # Apply histogram equalization for better contrast with a 30% chance\n",
    "    A.FancyPCA(alpha=0.1, p=0.3),  # Adjust color intensities using PCA for slight color augmentation\n",
    "    A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.3)  # Apply CLAHE to enhance contrast adaptively\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514234a5-191a-424e-87b1-9016509a5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=[]\n",
    "num_augmentations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82fe016-12e6-4f75-a687-b571bd285971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images in each directory\n",
    "for directory, label in zip(input_data_dir_list, DIRECTORY_LIST):\n",
    "    for img_filename in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_filename)\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        # Generate a new filename for the original image with class label prefix\n",
    "        original_new_filename = f\"{label}_{uuid.uuid4()}.jpg\"\n",
    "        original_output_path = os.path.join(output_data_dir, original_new_filename)\n",
    "        \n",
    "        # Save the original image with the new name\n",
    "        cv2.imwrite(original_output_path, image)\n",
    "        \n",
    "        # Append to metadata for the original image\n",
    "        metadata.append([original_new_filename, label])\n",
    "        \n",
    "        for _ in range(num_augmentations):\n",
    "            # Apply augmentation\n",
    "            augmented = augmentation_pipeline(image=image)['image']\n",
    "            \n",
    "            # Generate a new filename for the augmented image with class label prefix\n",
    "            new_filename = f\"{label}_{uuid.uuid4()}.jpg\"\n",
    "            \n",
    "            # Define output path for saving the augmented image\n",
    "            output_path = os.path.join(output_data_dir, new_filename)\n",
    "            \n",
    "            # Save augmented image\n",
    "            cv2.imwrite(output_path, augmented)\n",
    "            \n",
    "            # Append to metadata for the augmented image\n",
    "            metadata.append([new_filename, label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19c48d-70a6-496f-91da-36bd0bffe14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metadata to DataFrame and save to CSV\n",
    "metadata_df = pd.DataFrame(metadata, columns=['filename', 'class'])\n",
    "metadata_df.to_csv(output_metadata_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72f753-82ae-4f32-b2ab-a0d5ea5f3398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16225"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310tf2",
   "language": "python",
   "name": "py310tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
